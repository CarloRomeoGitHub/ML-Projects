{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProgettoDataAnalyticsCarloRomeo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarloRomeoGitHub/ML-exercises/blob/master/ProgettoDataAnalyticsCarloRomeo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNiSTxParKJ8",
        "colab_type": "text"
      },
      "source": [
        "Questo progetto verte sul problema della Multiclassificazione. Fa riferimento al dataset [*Intel-Image-Classification*](https://www.kaggle.com/puneet6060/intel-image-classification) di Kaggle.\n",
        "Questo dataset e' composto da sei classi riguardanti diversi paesaggi. Abbiamo:\n",
        "\n",
        "\n",
        "1.   Costruzioni\n",
        "2.   Mare\n",
        "3.   Montagna\n",
        "4.   Ghiacciai\n",
        "5.   Urbano\n",
        "6.   Foresta\n",
        "\n",
        "Le immagini che compongono il dataset sono delle immagini a colori di diversa misura che sono state opportunamente ridimensionate prima della fase di training.\n",
        "Per errori presenti nella porzione *Previsioni*, ho deciso di utilizzare la porzione *Test* per validazione e testing dividendola in parti uguali.\n",
        "L'obiettivo principale di questo progetto non e' la pretesa di sviluppare un motore ad elevate prestazioni ma, attraverso una corposa fase di tuning, capire come la rete si comporta con diverse configurazioni.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqW-Vw_CymtN",
        "colab_type": "text"
      },
      "source": [
        "Codice necessario per l'implementazione di TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alyPLptrL3gF",
        "colab_type": "code",
        "outputId": "b0002fee-0fc8-44b6-8685-ee87cc57b251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-09 12:53:59--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 50.17.165.171, 34.206.126.139, 34.196.175.208, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|50.17.165.171|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  18.2MB/s    in 0.7s    \n",
            "\n",
            "2020-02-09 12:54:00 (18.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iLZpP0AMURl",
        "colab_type": "code",
        "outputId": "ec4ef2c2-e5f3-43ba-bbbe-fd26eef95fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKcllz4UyoJl",
        "colab_type": "code",
        "outputId": "c047ee8f-0770-4034-ecb9-b3e7012009dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import tensorflow.keras.layers as Layers\n",
        "import tensorflow.keras.activations as Actications\n",
        "import tensorflow.keras.models as Models\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "import tensorflow.keras.metrics as Metrics\n",
        "import tensorflow.keras.utils as Utils\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHpLh3QPy14N",
        "colab_type": "text"
      },
      "source": [
        "Utilizziamo questa funzione per pulire direttamente il Drive sul quale stiamo lavorando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmM3yZ8LnfLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('../content/drive/My Drive/fold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzK2hwTIy-6l",
        "colab_type": "text"
      },
      "source": [
        "Tramite ZipFile possiamo estrarre lo zip precedentemente caricato sul Drive in una specifica cartella chiamata *fold* nel nostro caso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzE4ip010XEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('../content/drive/My Drive/intel-image-classification.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('../content/drive/My Drive/fold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01xwVUFAyab2",
        "colab_type": "text"
      },
      "source": [
        "Con questa funzione, tramite il parametro *directory* assegnamo le labels estrapolandole direttamente dal nome della cartella."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9cjsOo5ysEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  \n",
        "    label = 0\n",
        "    \n",
        "    for labels in os.listdir(directory): #Tramite il parametro directory definiamo ogni cartella con il nome della label\n",
        "        if labels == 'buildings': \n",
        "            label = 0\n",
        "        elif labels == 'forest':\n",
        "            label = 1\n",
        "        elif labels == 'glacier':\n",
        "            label = 2\n",
        "        elif labels == 'mountain':\n",
        "            label = 3\n",
        "        elif labels == 'sea':\n",
        "            label = 4\n",
        "        elif labels == 'street':\n",
        "            label = 5\n",
        "        \n",
        "        for image_file in os.listdir(directory+labels): #Componiamo il nome dell'immagine partendo dal Folder e dalla Label\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file) \n",
        "            image = cv2.resize(image,(150, 150))\n",
        "            image = image / 255 #Normalizzazione effettuata solo per il Modello 10   \n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "    \n",
        "    return shuffle(Images,Labels,random_state=42) \n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = { 0:'buildings', 1:'forest', 2:'glacier', 3:'mountain',  4:'sea', 5:'street' }\n",
        "    \n",
        "    return labels[class_code]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1-wqgfuyNNq",
        "colab_type": "text"
      },
      "source": [
        "Abbiamo estrapolato separatamente le immagini dai due insiemi in modo da non sovraccaricare la RAM, evitando cosi' eventuali perdite di dati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4S50wUCywYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Estrazione Dati\n",
        "Images_train, Labels_train = get_images('../content/drive/My Drive/fold/seg_train/seg_train/')\n",
        "\n",
        "Images_train = np.array(Images_train)\n",
        "Labels_train = np.array(Labels_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAcm3qcJBrt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Images_test, Labels_test = get_images('../content/drive/My Drive/fold/seg_test/seg_test/')\n",
        "\n",
        "numb = int(len(Images_test)/2)\n",
        "\n",
        "Images_val = Images_test[:numb]\n",
        "Images_val = np.array(Images_val)\n",
        "\n",
        "Labels_val = Labels_test[:numb]\n",
        "Labels_val = np.array(Labels_val)\n",
        "\n",
        "Images_test = Images_test[numb:]\n",
        "Images_test = np.array(Images_test)\n",
        "\n",
        "Labels_test = Labels_test[numb:]\n",
        "Labels_test = np.array(Labels_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KdaonoCOaLC",
        "colab_type": "text"
      },
      "source": [
        "Prima di lavorare sui dati visualizziamo qualche esempio prendendo qualche immagine random  dal nostro dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvw_cSdaLd3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualizzazione dei Dati\n",
        "fig = plot.figure(figsize=(30, 30))\n",
        "f,ax = plot.subplots(5,5) \n",
        "f.subplots_adjust(0,0,3,3)\n",
        "for i in range(0,5,1):\n",
        "    for j in range(0,5,1):\n",
        "        rnd_number = randint(0,len(Images_train))\n",
        "        ax[i,j].imshow(Images_train[rnd_number])\n",
        "        ax[i,j].set_title(get_classlabel(Labels_train[rnd_number]))\n",
        "        ax[i,j].axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71DNN6urzpVR",
        "colab_type": "text"
      },
      "source": [
        "Abbiamo utilizzato tre diverse callback per poter sfruttare al meglio il motore.\n",
        "\n",
        "1.   *EarlyStopper* viene utilizzata per evitare l'overfitting, questa fermera' il motore se dopo x epoche ( x viene definito dal parametro *patience*) la loss non decrementa. E' stato utilizzato inoltre il parametro *restore_best_weights* in modo da poter ripristinare i pesi migliori;\n",
        "\n",
        "2.  *TensorBoard* viene utilizzata per accedere all'omonimo tool, il quale fornisce una visualizzazione approfondita della rete;\n",
        "\n",
        "3.   *ModelCheckPoint* permette di salvare checkpoint del modello al termine di ogni epoca. Questo previene la perdita di dati per esempio per una disconnessione. Questa callback viene definita all'interno di ogni motore e non in maniera generica (come fatto per le altre) in modo da poter salvare ogni modello con un differente nome in modo immediato.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mdnqWL2KrFl",
        "colab_type": "code",
        "outputId": "c80d09e5-1a74-4f9d-beeb-13f0ecd53a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#CallBack\n",
        "\n",
        "earlystopper = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7, restore_best_weights=True)\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=100,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxlVefMIxurc",
        "colab_type": "text"
      },
      "source": [
        "Utilizziamo il metodo *load_model* in modo da poter caricare un modello precedentemente allenato per poterlo visualizzare tramite TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJg9z7wLuT2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.load_model('/content/model10Log45.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrsrbWje1tBq",
        "colab_type": "text"
      },
      "source": [
        "Questa codice permette di accedere alla propria sessione di TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE062MjJSgBv",
        "colab_type": "code",
        "outputId": "92b4c32c-4579-472b-e6b3-8ba5c594c72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://bd9281e8.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmQXAhpBO2Ag",
        "colab_type": "text"
      },
      "source": [
        "Qui abbiamo definito una *GridSearch* per poter trovare gli iperparamentri della rete, scandendo diverse combinazioni.\n",
        "Gli aspetti presi in considerazione sono:\n",
        "\n",
        "\n",
        "1.   Numero di filtri per ogni layer convoluzionale\n",
        "2.   Dimensione di ogni filtro\n",
        "3.   Presenza dello strides\n",
        "4.   Funzione di attivazione\n",
        "5.   Unita' di ogni layer denso\n",
        "6.   Valore del drop out\n",
        "\n",
        "Il modello con Grid Search per carenza di risorse computazionali, sebbene sia stato effettuato un tuning dei parametri esaminabili per trovare la configurazione minima, non e' eseguibile in quanto produce un *Memory Leak*.\n",
        "Per completezza e' stato comunque lasciato il modello.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNcW1Qb1AOPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "#GRID SEARCH MODEL\n",
        "def create_model(first_filt, sec_filt, third_filt, first_kern, sec_kern, third_kern, strides, activation, units, drop_out):\n",
        "  #DEFAULT PARAMS\n",
        "  first_filt = 64\n",
        "  sec_filt = 128\n",
        "  third_filt = 256\n",
        "  first_kern = 7\n",
        "  sec_kern = 5\n",
        "  third_kern = 3\n",
        "  strides = 2\n",
        "  activation = 'elu'\n",
        "  units = 64\n",
        "  drop_out = 0.5\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(first_filt, first_kern, activation = activation, padding = \"same\", input_shape = [150, 150, 3]))\n",
        "  model.add(Conv2D(first_filt, first_kern, activation = activation, padding = \"same\"))\n",
        "  model.add(AvgPool2D(2))\n",
        "\n",
        "  model.add(Conv2D(sec_filt,sec_kern, activation = activation, padding =\"same\"))\n",
        "  model.add(Conv2D(sec_filt,sec_kern, activation = activation, padding =\"same\", strides= 2)) \n",
        "  model.add(MaxPooling2D(2))\n",
        "\n",
        "  model.add(Conv2D(third_filt,third_kern, activation = activation, padding =\"same\"))\n",
        "  model.add(Conv2D(third_filt,third_kern, activation = activation, padding =\"same\"))\n",
        "  model.add(MaxPooling2D(2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(units, activation = activation))\n",
        "  model.add(Dropout(drop_out))\n",
        "\n",
        "  model.add(Dense(units, activation = activation))\n",
        "  model.add(Dropout(drop_out))\n",
        "\n",
        "  model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuAqxqiKIlWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXECUTE GRID SEARCH\n",
        "\n",
        "first_filt = [64, 128]\n",
        "sec_filt = [128, 256]\n",
        "third_filt = [256, 512]\n",
        "first_kern = [7, 5, 3]\n",
        "sec_kern = [5, 3]\n",
        "third_kern = [3, 1]\n",
        "strides = [2, 0]\n",
        "activation = ['elu', 'relu']\n",
        "units = [64, 128]\n",
        "drop_out = [0.5, 0.3, 0.1]\n",
        "\n",
        "param_grid = dict(first_filt = first_filt, sec_filt = sec_filt, third_filt = third_filt,\n",
        "                  first_kern = first_kern, sec_kern = sec_kern, third_kern = third_kern,\n",
        "                  strides = strides, activation = activation, units = units,\n",
        "                  drop_out = drop_out)\n",
        "model = KerasClassifier(build_fn = create_model, batch_size = 100, epochs = 30, verbose = 1)\n",
        "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = 1)\n",
        "grid.fit(Images_train, Labels_train)\n",
        "grid.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk0RfA20QbH_",
        "colab_type": "text"
      },
      "source": [
        "Troviamo *batch_size* relativamente basso poiche' valori elevati porterebbero ad un crash della rete a causa delle risorse limitate.\n",
        "I motori sono stati allenati su cento epoche di partenza. Ogni motore poi, a causa dell'overfitting, ha raggiunto un valore ottimale nell'intorno delle 30 epoche."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTuzZoqnZIk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EXECUTION PARAMS\n",
        "batch_size = 50\n",
        "epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4HhqUVpRoJQ",
        "colab_type": "text"
      },
      "source": [
        "Nella definizione di ogni modello si possono trovare, come commento, le prestazioni raggiunte dal modello in questione durante l'allenamento.\n",
        "Tale allenamento e' avvenuto sul dataset (Images_train, Labels_train) effettuando una validazione su (Images_val, Labels_val)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CLSy9HxXOdBl",
        "outputId": "500c648d-1c0a-4a5a-db78-ac951746beba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "#MODEL 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 25/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9291\n",
        "#Epoch 00025: loss improved from 0.21993 to 0.21744, saving model to unet_membrane.hdf5\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 75s 5ms/sample - loss: 0.2174 - accuracy: 0.9290 - val_loss: 0.6126 - val_accuracy: 0.8227\n",
        "#Epoch 00025: early stopping\n",
        "#Tests loss:  0.5204133424758911\n",
        "#Test accuracy:  0.82766664\n",
        "\n",
        "model.add(Conv2D(64, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64, 5, activation = \"elu\", padding = \"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model1.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model1.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 150, 150, 64)      9472      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 64)      102464    \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 75, 75, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 38, 38, 128)       409728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 19, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 19, 19, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 19, 19, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20736)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               2654336   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 4,274,822\n",
            "Trainable params: 4,274,822\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 14034 samples, validate on 1500 samples\n",
            "Epoch 1/3\n",
            "   50/14034 [..............................] - ETA: 41:00 - loss: 1.8362 - accuracy: 0.1400WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.163304). Check your callbacks.\n",
            "14000/14034 [============================>.] - ETA: 0s - loss: 3.1714 - accuracy: 0.1697\n",
            "Epoch 00001: loss improved from inf to 3.16902, saving model to model1.h5\n",
            "14034/14034 [==============================] - 49s 3ms/sample - loss: 3.1690 - accuracy: 0.1699 - val_loss: 1.8093 - val_accuracy: 0.1673\n",
            "Epoch 2/3\n",
            "14000/14034 [============================>.] - ETA: 0s - loss: 2.1131 - accuracy: 0.1694\n",
            "Epoch 00002: loss improved from 3.16902 to 2.11323, saving model to model1.h5\n",
            "14034/14034 [==============================] - 39s 3ms/sample - loss: 2.1132 - accuracy: 0.1692 - val_loss: 1.7979 - val_accuracy: 0.1847\n",
            "Epoch 3/3\n",
            "14000/14034 [============================>.] - ETA: 0s - loss: 2.0208 - accuracy: 0.1657\n",
            "Epoch 00003: loss improved from 2.11323 to 2.02025, saving model to model1.h5\n",
            "14034/14034 [==============================] - 39s 3ms/sample - loss: 2.0203 - accuracy: 0.1658 - val_loss: 1.7931 - val_accuracy: 0.1847\n",
            "Tests loss:  1.7932276601791381\n",
            "Test accuracy:  0.184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpTShXGvTQxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 31/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9529\n",
        "#Epoch 00031: loss did not improve from 0.14833\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 23s 2ms/sample - loss: 0.1563 - accuracy: 0.9529 - val_loss: 0.6264 - val_accuracy: 0.8530\n",
        "#Epoch 00031: early stopping\n",
        "#Tests loss:  0.5005115587711334\n",
        "#Test accuracy:  0.84066665\n",
        "\n",
        "model.add(Conv2D(64, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model2.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model2.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNF_jddwW5bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 3\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 31/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 0.9470\n",
        "#Epoch 00031: loss did not improve from 0.15335\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 88s 6ms/sample - loss: 0.1827 - accuracy: 0.9471 - val_loss: 0.7764 - val_accuracy: 0.8137\n",
        "#Epoch 00031: early stopping\n",
        "#Tests loss:  0.5321324812571208\n",
        "#Test accuracy:  0.826\n",
        "\n",
        "model.add(Conv2D(128, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(256,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,5, activation = \"elu\", padding =\"same\", strides= 3)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(512,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(512,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model3.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model3.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wslL-BzdKiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 4\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 54/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9315\n",
        "#Epoch 00054: loss improved from 0.22054 to 0.21993, saving model to unet_membrane.hdf5\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 91s 6ms/sample - loss: 0.2199 - accuracy: 0.9315 - val_loss: 1.1133 - val_accuracy: 0.7920\n",
        "#Epoch 00054: early stopping\n",
        "#Tests loss:  0.6018184332052866\n",
        "#Test accuracy:  0.81633335\n",
        "\n",
        "model.add(Conv2D(64, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(512,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model4.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model4.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0tRgowlT-NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 5\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 30/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.2361 - accuracy: 0.9238\n",
        "#Epoch 00030: loss did not improve from 0.21374\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 40s 3ms/sample - loss: 0.2360 - accuracy: 0.9238 - val_loss: 0.7770 - val_accuracy: 0.8253\n",
        "#Epoch 00030: early stopping\n",
        "#Tests loss:  0.4971700879732768\n",
        "#Test accuracy:  0.8383333\n",
        "\n",
        "model.add(Conv2D(64, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64,7, activation = \"elu\", padding =\"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model5.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model5.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C3YEcG1QfEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 6\n",
        "\n",
        "model = Sequential()\n",
        "# Epoch 35/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9537\n",
        "#Epoch 00035: loss improved from 0.15810 to 0.15335, saving model to unet_membrane.hdf5\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 65s 5ms/sample - loss: 0.1533 - accuracy: 0.9538 - val_loss: 0.7257 - val_accuracy: 0.8337\n",
        "#Epoch 00035: early stopping\n",
        "#Tests loss:  0.5391829943656922\n",
        "#Test accuracy:  0.844\n",
        "\n",
        "model.add(Conv2D(64, 5, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model6.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model6.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTIMF3HHVTRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 7\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Epoch 26/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.2663 - accuracy: 0.9120\n",
        "#Epoch 00026: loss did not improve from 0.21993\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 78s 6ms/sample - loss: 0.2660 - accuracy: 0.9121 - val_loss: 0.5647 - val_accuracy: 0.8480\n",
        "#Epoch 00026: early stopping\n",
        "#Tests loss:  0.5447170452276866\n",
        "#Test accuracy:  0.80333334\n",
        "\n",
        "model.add(Conv2D(64, 5, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model7.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model7.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm2ACyVMji5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 8\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 24/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9608\n",
        "#Epoch 00024: loss improved from 0.12924 to 0.12422, saving model to unet_membrane.hdf5\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 68s 5ms/sample - loss: 0.1242 - accuracy: 0.9607 - val_loss: 0.6579 - val_accuracy: 0.8350\n",
        "#Epoch 00024: early stopping\n",
        "#Tests loss:  0.4827573082447052\n",
        "#Test accuracy:  0.849\n",
        "\n",
        "model.add(Conv2D(64, 5, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,3, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model8.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model8.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttx6kmwCPcyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 9 \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 26/100\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.9282\n",
        "#Epoch 00026: loss did not improve from 0.21374\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 40s 3ms/sample - loss: 0.2194 - accuracy: 0.9284 - val_loss: 0.6504 - val_accuracy: 0.8003\n",
        "#Epoch 00026: early stopping\n",
        "#Tests loss:  0.47910083723068236\n",
        "#Test accuracy:  0.8436667\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64, 5, activation = \"elu\", padding = \"same\"))\n",
        "model.add(AvgPool2D(2))\n",
        "\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\", strides= 2)) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(512,1, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(512,1, activation = \"elu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model9.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model9.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrdbVDTJ2IgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL 10\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Epoch 26/50\n",
        "#14000/14034 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9285\n",
        "#Epoch 00026: loss improved from 0.23279 to 0.20969, saving model to model10.h5\n",
        "#Restoring model weights from the end of the best epoch\n",
        "#14034/14034 [==============================] - 40s 3ms/sample - loss: 0.2097 - accuracy: 0.9284 - val_loss: 0.5325 - val_accuracy: 0.8480\n",
        "#Epoch 00026: early stopping\n",
        "#Tests loss:  0.45385681772232056\n",
        "#Test accuracy:  0.83933336\n",
        "\n",
        "model.add(Conv2D(64, 7, activation = \"elu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "model.add(Conv2D(64, 5, activation = \"elu\", padding = \"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,5, activation = \"elu\", padding =\"same\", strides= 2))\n",
        "model.add(BatchNormalization()) \n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"elu\", padding =\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Conv2D(512,1, activation = \"elu\", padding =\"same\"))\n",
        "model.add(Conv2D(512,1, activation = \"elu\", padding =\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation = \"elu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('model10.h5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(Images_train, Labels_train, batch_size=batch_size, epochs=epochs, verbose = 1, validation_data=(Images_val, Labels_val), callbacks=[model_checkpoint, earlystopper, tensorboard_callback])\n",
        "score = model.evaluate(Images_test, Labels_test, verbose = 0)\n",
        "print(\"Tests loss: \", score[0])\n",
        "print(\"Test accuracy: \", score[1])\n",
        "model.save('model10.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E_w9hf_SiMT",
        "colab_type": "text"
      },
      "source": [
        "Dal confronto tra le diverse perfomance dei dieci motori realizzati emerge che la miglior configurazione realizzata e' l'ultima.\n",
        "Per la realizzazione di ogni motore e' stata osservata la realizzazione del precedente, traendo da ogni tentativo spunti per il miglioramento della rete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkj8XrbZtefi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict_classes(Images_test[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KmLR5mbVUFw",
        "colab_type": "code",
        "outputId": "70447574-e81c-440b-f1ac-18870fa2c370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(result, Labels_test[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 1 3 5 4 3 3 4] [0 0 1 1 3 5 4 3 5 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaYsfxM7nkIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}