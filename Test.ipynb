{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Mpvn_3SZjyk8mUupFU7HQGvXYiy7RZan",
      "authorship_tag": "ABX9TyOKAisXUC+9w5adyy60Zf+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarloRomeoGitHub/ML-exercises/blob/master/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKcllz4UyoJl",
        "colab_type": "code",
        "outputId": "96c22881-cc06-46be-cdc8-7ce54fcfa08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL\n",
        "import skimage as sk\n",
        "import random\n",
        "from zipfile import ZipFile\n",
        "import tensorflow.keras.layers as Layers\n",
        "import tensorflow.keras.activations as Actications\n",
        "import tensorflow.keras.models as Models\n",
        "import tensorflow.keras.optimizers as Optimizer\n",
        "import tensorflow.keras.metrics as Metrics\n",
        "import tensorflow.keras.utils as Utils\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import os\n",
        "import matplotlib.pyplot as plot\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix as CM\n",
        "from random import randint\n",
        "from IPython.display import SVG\n",
        "import matplotlib.gridspec as gridspec"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmM3yZ8LnfLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import shutil\n",
        "\n",
        "#shutil.rmtree('../root/tensorflow_datasets')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzE4ip010XEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "2\n",
        "3\n",
        "4\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile('../content/drive/My Drive/intel-image-classification.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall('../content/drive/My Drive/intel')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9cjsOo5ysEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_images(directory):\n",
        "    Images = []\n",
        "    Labels = []  # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street\n",
        "    label = 0\n",
        "    \n",
        "    for labels in os.listdir(directory): #Main Directory where each class label is present as folder name.\n",
        "        if labels == 'glacier': #Folder contain Glacier Images get the '2' class label.\n",
        "            label = 2\n",
        "        elif labels == 'sea':\n",
        "            label = 4\n",
        "        elif labels == 'buildings':\n",
        "            label = 0\n",
        "        elif labels == 'forest':\n",
        "            label = 1\n",
        "        elif labels == 'street':\n",
        "            label = 5\n",
        "        elif labels == 'mountain':\n",
        "            label = 3\n",
        "        \n",
        "        for image_file in os.listdir(directory+labels): #Extracting the file name of the image from Class Label folder\n",
        "            image = cv2.imread(directory+labels+r'/'+image_file) #Reading the image (OpenCV)\n",
        "            image = cv2.resize(image,(150,150)) #Resize the image, Some images are different sizes. (Resizing is very Important)\n",
        "            Images.append(image)\n",
        "            Labels.append(label)\n",
        "    \n",
        "    return shuffle(Images,Labels,random_state=817328462) #Shuffle the dataset you just prepared.\n",
        "\n",
        "def get_classlabel(class_code):\n",
        "    labels = {2:'glacier', 4:'sea', 0:'buildings', 1:'forest', 5:'street', 3:'mountain'}\n",
        "    \n",
        "    return labels[class_code]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4S50wUCywYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Images, Labels = get_images('../content/drive/My Drive/intel/seg_train/seg_train/') #Extract the training images from the folders.\n",
        "\n",
        "Images_train = np.array(Images) #converting the list of images to numpy array.\n",
        "Labels_train = np.array(Labels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAcm3qcJBrt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Images_test, Labels_test = get_images('../content/drive/My Drive/intel/seg_test/seg_test/') #Extract the training images from the folders.\n",
        "\n",
        "Images_test = np.array(Images_test) #converting the list of images to numpy array.\n",
        "Labels_test = np.array(Labels_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCgGM8OrJEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Images_pred, Labels_pred = get_images('../content/drive/My Drive/intel/seg_pred/seg_pred/') #Extract the training images from the folders.\n",
        "\n",
        "Images_pred = np.array(Images_pred) #converting the list of images to numpy array.\n",
        "Labels_pred = np.array(Labels_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kS80c3B1-A4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "9333fe94-063b-406d-900d-7ea0452630a6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, 7, activation = \"relu\", padding = \"same\", input_shape = [150, 150, 3]))\n",
        "\n",
        "#Parametri:\n",
        "#7x7=49 pesi\n",
        "#1 bias\n",
        "#50 parametri; 50 x 64 = 3200\n",
        "\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Conv2D(128,3, activation = \"relu\", padding =\"same\"))\n",
        "model.add(Conv2D(128,3, activation = \"relu\", padding =\"same\")) \n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Conv2D(256,3, activation = \"relu\", padding =\"same\"))\n",
        "model.add(Conv2D(256,3, activation = \"relu\", padding =\"same\"))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#layer di dropout(attivo solo in fase di addestramento): server per evitare l'overfittng e facilitare il learning.\n",
        "#Durante l'addestramente inibisce ad ogni passo una percentuale di neuroni, e cerca di far riconoscere gli oggetti usando solo una parte di neuroni\n",
        "# 0.5 Ã¨ la percentuale di neuroni che escludo dal task\n",
        "\n",
        "\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "#compilazione modello \n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 150, 150, 64)      9472      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 82944)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               10616960  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 11,750,922\n",
            "Trainable params: 11,750,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGqCW-BpzIfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "\n",
        "earlystopper = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrdbVDTJ2IgU",
        "colab_type": "code",
        "outputId": "67bca751-9f8f-4551-d7d4-8e12a27f69dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "model.fit(Images_train, Labels_train, batch_size=50, epochs=30, callbacks=[model_checkpoint, earlystopper])\n",
        "model.evaluate(Images_test, Labels_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14034 samples\n",
            "Epoch 1/30\n",
            "14000/14034 [============================>.] - ETA: 0s - loss: 2.5828 - acc: 0.2799\n",
            "Epoch 00001: loss did not improve from 0.08498\n",
            "14034/14034 [==============================] - 47s 3ms/sample - loss: 2.5802 - acc: 0.2802\n",
            "Epoch 2/30\n",
            "   50/14034 [..............................] - ETA: 46s - loss: 1.3561 - acc: 0.4600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "14000/14034 [============================>.] - ETA: 0s - loss: 1.2472 - acc: 0.4902\n",
            "Epoch 00002: loss did not improve from 0.08498\n",
            "14034/14034 [==============================] - 47s 3ms/sample - loss: 1.2471 - acc: 0.4903\n",
            "Epoch 3/30\n",
            "14000/14034 [============================>.] - ETA: 0s - loss: 1.0828 - acc: 0.5635\n",
            "Epoch 00003: loss did not improve from 0.08498\n",
            "14034/14034 [==============================] - 47s 3ms/sample - loss: 1.0825 - acc: 0.5638\n",
            "Epoch 4/30\n",
            "  700/14034 [>.............................] - ETA: 44s - loss: 1.1027 - acc: 0.5629"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}